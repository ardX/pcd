{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modul Pengolahan Citra Digital (PCD)\n",
        "\n",
        "```\n",
        "pip install opencv-python scipy scikit-image matplotlib\n",
        "```\n",
        "\n",
        "## Daftar Isi\n",
        "\n",
        "1. Definisi dan Manfaat PCD\n",
        "2. Level-level dan Berbagai Operasi pada PCD\n",
        "3. Konsep Persepsi Visual, Fenomena Visual, Spektrum Cahaya dan Gelombang Elektromagnetik\n",
        "4. Akuisisi Citra, Proses Pembentukan Citra Digital, serta Penggunaan PCD\n",
        "5. Operasi Titik Geometrik\n",
        "6. Transformasi Tingkat Keabuan pada Citra\n",
        "7. Interpretasi Histogram\n",
        "8. Ekualisasi Histogram dan Histogram Matching\n",
        "9. Operasi Morfologi\n",
        "10. Konvolusi dan Filtering\n",
        "11. Transformasi Domain Frekuensi\n",
        "12. Pyramids, Edge Detection, dan Feature Detection/Description\n",
        "13. Pengolahan Citra Berwarna\n",
        "14. Segmentasi Citra\n",
        "15. Kompresi Citra\n",
        "16. Aplikasi PCD di Berbagai Bidang Sains dan Medical Imaging\n",
        "17. State of the Art PCD di Berbagai Bidang\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import library yang diperlukan\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import ndimage, signal\n",
        "from skimage import filters, feature, segmentation, color, exposure, morphology, transform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style untuk plotting\n",
        "plt.style.use('default')\n",
        "np.set_printoptions(precision=3, suppress=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Definisi dan Manfaat PCD\n",
        "\n",
        "## Definisi Pengolahan Citra Digital (PCD)\n",
        "\n",
        "**Pengolahan Citra Digital (Digital Image Processing)** adalah proses manipulasi dan analisis citra digital menggunakan algoritma komputer untuk meningkatkan kualitas citra, mengekstrak informasi, atau melakukan analisis otomatis.\n",
        "\n",
        "### Karakteristik Citra Digital:\n",
        "- Citra digital adalah representasi diskrit dari citra kontinyu\n",
        "- Terdiri dari array dua dimensi (atau tiga dimensi untuk citra berwarna) dari nilai-nilai piksel\n",
        "- Setiap piksel memiliki koordinat (x, y) dan nilai intensitas\n",
        "\n",
        "## Manfaat PCD\n",
        "\n",
        "1. **Peningkatan Kualitas Citra**: Memperbaiki kontras, mengurangi noise, memperjelas detail\n",
        "2. **Ekstraksi Informasi**: Mendeteksi objek, mengukur parameter, menganalisis pola\n",
        "3. **Otomasi**: Proses yang dapat dilakukan secara otomatis tanpa intervensi manusia\n",
        "4. **Kompresi**: Mengurangi ukuran file citra untuk efisiensi penyimpanan dan transmisi\n",
        "5. **Restorasi**: Memperbaiki citra yang rusak atau terdegradasi\n",
        "6. **Analisis Medis**: Diagnosis melalui citra medis (X-ray, CT scan, MRI)\n",
        "7. **Pengenalan Pola**: Face recognition, OCR, deteksi objek\n",
        "8. **Computer Vision**: Sistem yang dapat \"melihat\" dan memahami citra\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Level-level dan Berbagai Operasi pada PCD\n",
        "\n",
        "## Level-level Pengolahan Citra\n",
        "\n",
        "### 1. **Level Rendah (Low-level Processing)**\n",
        "- Operasi pada level piksel\n",
        "- Input dan output berupa citra\n",
        "- Contoh: noise reduction, sharpening, contrast enhancement\n",
        "\n",
        "### 2. **Level Menengah (Mid-level Processing)**\n",
        "- Operasi pada level objek/region\n",
        "- Input: citra, Output: atribut objek\n",
        "- Contoh: segmentasi, deteksi edge, deteksi corner\n",
        "\n",
        "### 3. **Level Tinggi (High-level Processing)**\n",
        "- Operasi pada level semantik\n",
        "- Input: atribut objek, Output: interpretasi/pengetahuan\n",
        "- Contoh: object recognition, scene understanding, decision making\n",
        "\n",
        "## Kategori Operasi PCD\n",
        "\n",
        "1. **Operasi Titik (Point Operations)**: Operasi pada setiap piksel secara independen\n",
        "2. **Operasi Spasial (Spatial Operations)**: Operasi yang melibatkan neighborhood piksel\n",
        "3. **Operasi Geometrik (Geometric Operations)**: Transformasi geometri seperti rotasi, scaling\n",
        "4. **Operasi Morfologi (Morphological Operations)**: Operasi berbasis struktur\n",
        "5. **Operasi Domain Frekuensi (Frequency Domain Operations)**: Operasi dalam domain Fourier/Wavelet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Konsep Persepsi Visual, Fenomena Visual, Spektrum Cahaya dan Gelombang Elektromagnetik\n",
        "\n",
        "## Persepsi Visual\n",
        "\n",
        "Persepsi visual adalah proses bagaimana sistem visual manusia menginterpretasikan informasi dari cahaya yang masuk ke mata.\n",
        "\n",
        "### Komponen Sistem Visual:\n",
        "- **Mata**: Sensor yang menangkap cahaya\n",
        "- **Retina**: Mengandung sel fotoreseptor (rods dan cones)\n",
        "- **Optic Nerve**: Mengirimkan sinyal ke otak\n",
        "- **Visual Cortex**: Memproses informasi visual\n",
        "\n",
        "## Fenomena Visual\n",
        "\n",
        "1. **Adaptasi**: Kemampuan mata menyesuaikan dengan tingkat kecerahan\n",
        "2. **Kontras**: Perbedaan intensitas antara objek dan latar belakang\n",
        "3. **Acuity**: Ketajaman visual\n",
        "4. **Color Vision**: Persepsi warna melalui tiga jenis cones (trichromacy)\n",
        "\n",
        "## Spektrum Cahaya dan Gelombang Elektromagnetik\n",
        "\n",
        "### Spektrum Elektromagnetik:\n",
        "- **Visible Light**: 400-700 nm (violet hingga red)\n",
        "- **Infrared**: > 700 nm\n",
        "- **Ultraviolet**: < 400 nm\n",
        "- **X-ray, Gamma ray**: Untuk medical imaging\n",
        "\n",
        "### Warna dalam Spektrum Visible:\n",
        "- **Violet**: ~400-450 nm\n",
        "- **Blue**: ~450-495 nm\n",
        "- **Green**: ~495-570 nm\n",
        "- **Yellow**: ~570-590 nm\n",
        "- **Orange**: ~590-620 nm\n",
        "- **Red**: ~620-700 nm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi spektrum elektromagnetik\n",
        "wavelengths = np.linspace(400, 700, 300)\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, 300))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 2))\n",
        "for i, (w, c) in enumerate(zip(wavelengths, colors)):\n",
        "    ax.axvspan(w, w+1, color=c, alpha=0.8)\n",
        "\n",
        "ax.set_xlim(400, 700)\n",
        "ax.set_xlabel('Wavelength (nm)')\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Visible Light Spectrum')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Akuisisi Citra, Proses Pembentukan Citra Digital, serta Penggunaan PCD\n",
        "\n",
        "## Akuisisi Citra\n",
        "\n",
        "Akuisisi citra adalah proses menangkap citra dari dunia nyata menjadi bentuk digital.\n",
        "\n",
        "### Komponen Sistem Akuisisi:\n",
        "1. **Sumber Cahaya**: Illuminasi objek\n",
        "2. **Lensa**: Memfokuskan cahaya\n",
        "3. **Sensor**: Menangkap cahaya (CCD/CMOS)\n",
        "4. **ADC (Analog-to-Digital Converter)**: Mengkonversi sinyal analog ke digital\n",
        "5. **Storage**: Menyimpan data digital\n",
        "\n",
        "## Proses Pembentukan Citra Digital\n",
        "\n",
        "### Tahapan:\n",
        "1. **Sampling**: Mengambil sampel citra kontinyu pada interval diskrit\n",
        "2. **Quantization**: Mengkonversi nilai kontinyu menjadi nilai diskrit (levels)\n",
        "3. **Encoding**: Menyimpan sebagai array numerik\n",
        "\n",
        "### Parameter Penting:\n",
        "- **Spatial Resolution**: Jumlah piksel (misal: 1920x1080)\n",
        "- **Intensity Resolution**: Jumlah level intensitas (misal: 256 levels untuk 8-bit)\n",
        "- **Color Depth**: Jumlah bit per channel (8-bit, 16-bit, dll)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrasi pembacaan dan properti citra digital\n",
        "img = cv2.imread(\"images/mandrill.jpg\", cv2.IMREAD_COLOR)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "print(\"Shape citra berwarna:\", img.shape)\n",
        "print(\"Shape citra grayscale:\", img_gray.shape)\n",
        "print(\"Tipe data:\", img.dtype)\n",
        "print(\"Range nilai:\", img.min(), \"-\", img.max())\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title('Citra Berwarna (RGB)')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_gray, cmap='gray')\n",
        "axes[1].set_title('Citra Grayscale')\n",
        "axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Operasi Titik Geometrik\n",
        "\n",
        "Operasi geometrik mengubah posisi atau orientasi piksel dalam citra.\n",
        "\n",
        "## 1. Flipping (Pencerminan)\n",
        "\n",
        "### Horizontal Flip (Flopping)\n",
        "### Vertical Flip (Flipping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flipping operations\n",
        "img = cv2.imread(\"images/mandrill.jpg\", cv2.IMREAD_COLOR)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Horizontal flip (flop)\n",
        "flip_horizontal = cv2.flip(img_rgb, 1)\n",
        "\n",
        "# Vertical flip (flip)\n",
        "flip_vertical = cv2.flip(img_rgb, 0)\n",
        "\n",
        "# Both horizontal and vertical\n",
        "flip_both = cv2.flip(img_rgb, -1)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(flip_horizontal)\n",
        "axes[0,1].set_title('Horizontal Flip (Flopping)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(flip_vertical)\n",
        "axes[1,0].set_title('Vertical Flip (Flipping)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(flip_both)\n",
        "axes[1,1].set_title('Both Directions')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Rotating (Rotasi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rotation operations\n",
        "h, w = img_rgb.shape[:2]\n",
        "center = (w // 2, h // 2)\n",
        "\n",
        "# Rotate 45 degrees\n",
        "M_45 = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
        "rotated_45 = cv2.warpAffine(img_rgb, M_45, (w, h))\n",
        "\n",
        "# Rotate 90 degrees\n",
        "M_90 = cv2.getRotationMatrix2D(center, 90, 1.0)\n",
        "rotated_90 = cv2.warpAffine(img_rgb, M_90, (w, h))\n",
        "\n",
        "# Rotate -30 degrees\n",
        "M_neg30 = cv2.getRotationMatrix2D(center, -30, 1.0)\n",
        "rotated_neg30 = cv2.warpAffine(img_rgb, M_neg30, (w, h))\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(rotated_45)\n",
        "axes[0,1].set_title('Rotated 45°')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(rotated_90)\n",
        "axes[1,0].set_title('Rotated 90°')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(rotated_neg30)\n",
        "axes[1,1].set_title('Rotated -30°')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cropping (Pemotongan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cropping operations\n",
        "h, w = img_rgb.shape[:2]\n",
        "\n",
        "# Crop center region\n",
        "crop_center = img_rgb[h//4:3*h//4, w//4:3*w//4]\n",
        "\n",
        "# Crop specific region\n",
        "crop_specific = img_rgb[50:200, 100:250]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title('Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(crop_center)\n",
        "axes[1].set_title('Cropped Center')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(crop_specific)\n",
        "axes[2].set_title('Cropped Specific Region')\n",
        "axes[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Downsampling dan Upsampling\n",
        "\n",
        "**Downsampling**: Mengurangi resolusi citra (mengecilkan ukuran)\n",
        "**Upsampling**: Meningkatkan resolusi citra (memperbesar ukuran)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Downsampling and Upsampling\n",
        "h, w = img_rgb.shape[:2]\n",
        "\n",
        "# Downsampling - reduce size by half\n",
        "downsampled = cv2.resize(img_rgb, (w//2, h//2), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# Downsampling - reduce to 1/4 size\n",
        "downsampled_quarter = cv2.resize(img_rgb, (w//4, h//4), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# Upsampling - double the size\n",
        "upsampled = cv2.resize(img_rgb, (w*2, h*2), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# Upsampling with different interpolation methods\n",
        "upsampled_cubic = cv2.resize(img_rgb, (w*2, h*2), interpolation=cv2.INTER_CUBIC)\n",
        "upsampled_lanczos = cv2.resize(img_rgb, (w*2, h*2), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title(f'Original ({w}x{h})')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(downsampled)\n",
        "axes[0,1].set_title(f'Downsampled 1/2 ({w//2}x{h//2})')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(downsampled_quarter)\n",
        "axes[0,2].set_title(f'Downsampled 1/4 ({w//4}x{h//4})')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(upsampled)\n",
        "axes[1,0].set_title(f'Upsampled 2x Linear ({w*2}x{h*2})')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(upsampled_cubic)\n",
        "axes[1,1].set_title(f'Upsampled 2x Cubic')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(upsampled_lanczos)\n",
        "axes[1,2].set_title(f'Upsampled 2x Lanczos')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Transformasi Tingkat Keabuan pada Citra\n",
        "\n",
        "Transformasi tingkat keabuan mengubah nilai intensitas piksel berdasarkan fungsi transformasi.\n",
        "\n",
        "## 1. Operasi Aritmetika\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arithmetic operations on grayscale image\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Addition (brightening)\n",
        "brightened = cv2.add(img_gray, 50)\n",
        "\n",
        "# Subtraction (darkening)\n",
        "darkened = cv2.subtract(img_gray, 50)\n",
        "\n",
        "# Multiplication (contrast enhancement)\n",
        "multiplied = cv2.multiply(img_gray, 1.5).astype(np.uint8)\n",
        "\n",
        "# Division (contrast reduction)\n",
        "divided = cv2.divide(img_gray, 1.5).astype(np.uint8)\n",
        "\n",
        "# Image addition (blending)\n",
        "img2 = cv2.imread(\"images/lincoln.png\", cv2.IMREAD_GRAYSCALE)\n",
        "if img2 is not None:\n",
        "    img2_resized = cv2.resize(img2, (img_gray.shape[1], img_gray.shape[0]))\n",
        "    blended = cv2.addWeighted(img_gray, 0.7, img2_resized, 0.3, 0)\n",
        "else:\n",
        "    blended = img_gray\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(brightened, cmap='gray')\n",
        "axes[0,1].set_title('Brightened (+50)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(darkened, cmap='gray')\n",
        "axes[0,2].set_title('Darkened (-50)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(multiplied, cmap='gray')\n",
        "axes[1,0].set_title('Multiplied (×1.5)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(divided, cmap='gray')\n",
        "axes[1,1].set_title('Divided (÷1.5)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(blended, cmap='gray')\n",
        "axes[1,2].set_title('Blended')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Thresholding\n",
        "\n",
        "Thresholding mengkonversi citra grayscale menjadi citra biner (hitam-putih).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Thresholding operations\n",
        "# Simple thresholding\n",
        "_, thresh_binary = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "_, thresh_binary_inv = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "_, thresh_trunc = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TRUNC)\n",
        "_, thresh_tozero = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO)\n",
        "_, thresh_tozero_inv = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO_INV)\n",
        "\n",
        "# Adaptive thresholding\n",
        "thresh_adaptive_mean = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
        "                                             cv2.THRESH_BINARY, 11, 2)\n",
        "thresh_adaptive_gauss = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                               cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "# Otsu's thresholding\n",
        "_, thresh_otsu = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(thresh_binary, cmap='gray')\n",
        "axes[0,1].set_title('Binary')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(thresh_binary_inv, cmap='gray')\n",
        "axes[0,2].set_title('Binary Inverted')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(thresh_trunc, cmap='gray')\n",
        "axes[1,0].set_title('Truncated')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(thresh_tozero, cmap='gray')\n",
        "axes[1,1].set_title('To Zero')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(thresh_tozero_inv, cmap='gray')\n",
        "axes[1,2].set_title('To Zero Inverted')\n",
        "axes[1,2].axis('off')\n",
        "\n",
        "axes[2,0].imshow(thresh_adaptive_mean, cmap='gray')\n",
        "axes[2,0].set_title('Adaptive Mean')\n",
        "axes[2,0].axis('off')\n",
        "\n",
        "axes[2,1].imshow(thresh_adaptive_gauss, cmap='gray')\n",
        "axes[2,1].set_title('Adaptive Gaussian')\n",
        "axes[2,1].axis('off')\n",
        "\n",
        "axes[2,2].imshow(thresh_otsu, cmap='gray')\n",
        "axes[2,2].set_title(\"Otsu's Thresholding\")\n",
        "axes[2,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Lookup Tables (LUT)\n",
        "\n",
        "Lookup Tables adalah metode efisien untuk transformasi intensitas menggunakan tabel pemetaan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lookup Tables (LUT) examples\n",
        "# Create LUT for negative transformation\n",
        "lut_negative = np.array([255 - i for i in np.arange(256)], dtype=np.uint8)\n",
        "\n",
        "# Create LUT for gamma correction (gamma = 0.5)\n",
        "gamma = 0.5\n",
        "lut_gamma = np.array([((i / 255.0) ** (1.0 / gamma)) * 255 for i in np.arange(256)], dtype=np.uint8)\n",
        "\n",
        "# Create LUT for contrast stretching\n",
        "def create_contrast_lut(r1, s1, r2, s2):\n",
        "    lut = np.zeros(256, dtype=np.uint8)\n",
        "    for i in range(256):\n",
        "        if i <= r1:\n",
        "            lut[i] = int((s1 / r1) * i)\n",
        "        elif i <= r2:\n",
        "            lut[i] = int(((s2 - s1) / (r2 - r1)) * (i - r1) + s1)\n",
        "        else:\n",
        "            lut[i] = int(((255 - s2) / (255 - r2)) * (i - r2) + s2)\n",
        "    return lut\n",
        "\n",
        "lut_contrast = create_contrast_lut(50, 30, 200, 220)\n",
        "\n",
        "# Apply LUTs\n",
        "img_negative = cv2.LUT(img_gray, lut_negative)\n",
        "img_gamma = cv2.LUT(img_gray, lut_gamma)\n",
        "img_contrast = cv2.LUT(img_gray, lut_contrast)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(img_negative, cmap='gray')\n",
        "axes[0,1].set_title('Negative (LUT)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(img_gamma, cmap='gray')\n",
        "axes[1,0].set_title('Gamma Correction (LUT, γ=0.5)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(img_contrast, cmap='gray')\n",
        "axes[1,1].set_title('Contrast Stretching (LUT)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot LUT functions\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "x = np.arange(256)\n",
        "ax.plot(x, lut_negative, label='Negative', linewidth=2)\n",
        "ax.plot(x, lut_gamma, label='Gamma (γ=0.5)', linewidth=2)\n",
        "ax.plot(x, lut_contrast, label='Contrast Stretching', linewidth=2)\n",
        "ax.plot(x, x, 'k--', label='Identity', linewidth=1)\n",
        "ax.set_xlabel('Input Intensity')\n",
        "ax.set_ylabel('Output Intensity')\n",
        "ax.set_title('Lookup Table Functions')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Interpretasi Histogram\n",
        "\n",
        "Histogram citra menunjukkan distribusi frekuensi nilai intensitas piksel dalam citra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogram interpretation\n",
        "hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])\n",
        "\n",
        "# Calculate statistics\n",
        "mean_intensity = np.mean(img_gray)\n",
        "std_intensity = np.std(img_gray)\n",
        "median_intensity = np.median(img_gray)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "axes[0].imshow(img_gray, cmap='gray')\n",
        "axes[0].set_title('Grayscale Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].plot(hist, color='black')\n",
        "axes[1].axvline(mean_intensity, color='r', linestyle='--', label=f'Mean: {mean_intensity:.1f}')\n",
        "axes[1].axvline(median_intensity, color='g', linestyle='--', label=f'Median: {median_intensity:.1f}')\n",
        "axes[1].set_xlabel('Pixel Intensity')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Histogram')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Mean Intensity: {mean_intensity:.2f}\")\n",
        "print(f\"Standard Deviation: {std_intensity:.2f}\")\n",
        "print(f\"Median Intensity: {median_intensity:.2f}\")\n",
        "print(f\"Min Intensity: {img_gray.min()}\")\n",
        "print(f\"Max Intensity: {img_gray.max()}\")\n",
        "\n",
        "# Interpretasi histogram\n",
        "if std_intensity < 30:\n",
        "    print(\"\\nInterpretasi: Citra memiliki kontras rendah (histogram sempit)\")\n",
        "elif std_intensity > 60:\n",
        "    print(\"\\nInterpretasi: Citra memiliki kontras tinggi (histogram lebar)\")\n",
        "else:\n",
        "    print(\"\\nInterpretasi: Citra memiliki kontras sedang\")\n",
        "\n",
        "if mean_intensity < 85:\n",
        "    print(\"Citra cenderung gelap\")\n",
        "elif mean_intensity > 170:\n",
        "    print(\"Citra cenderung terang\")\n",
        "else:\n",
        "    print(\"Citra memiliki kecerahan sedang\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Ekualisasi Histogram dan Histogram Matching\n",
        "\n",
        "## Ekualisasi Histogram\n",
        "\n",
        "Ekualisasi histogram adalah teknik untuk meningkatkan kontras citra dengan menyebarkan distribusi intensitas secara merata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogram Equalization\n",
        "equ = cv2.equalizeHist(img_gray)\n",
        "\n",
        "# Calculate histograms\n",
        "hist_original = cv2.calcHist([img_gray], [0], None, [256], [0, 256])\n",
        "hist_equalized = cv2.calcHist([equ], [0], None, [256], [0, 256])\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original Image')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(equ, cmap='gray')\n",
        "axes[0,1].set_title('Histogram Equalized')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].plot(hist_original, color='black')\n",
        "axes[1,0].set_xlabel('Pixel Intensity')\n",
        "axes[1,0].set_ylabel('Frequency')\n",
        "axes[1,0].set_title('Original Histogram')\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1,1].plot(hist_equalized, color='black')\n",
        "axes[1,1].set_xlabel('Pixel Intensity')\n",
        "axes[1,1].set_ylabel('Frequency')\n",
        "axes[1,1].set_title('Equalized Histogram')\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "clahe_img = clahe.apply(img_gray)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "axes[0].imshow(img_gray, cmap='gray')\n",
        "axes[0].set_title('Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(equ, cmap='gray')\n",
        "axes[1].set_title('Global Histogram Equalization')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(clahe_img, cmap='gray')\n",
        "axes[2].set_title('CLAHE (Adaptive)')\n",
        "axes[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Histogram Matching (Specification)\n",
        "\n",
        "Histogram matching mengubah histogram citra agar sesuai dengan histogram target.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogram Matching\n",
        "from skimage import exposure\n",
        "\n",
        "# Load target image for histogram matching\n",
        "target_img = cv2.imread(\"images/lincoln.png\", cv2.IMREAD_GRAYSCALE)\n",
        "if target_img is None:\n",
        "    # Create a synthetic target with different histogram\n",
        "    target_img = np.random.normal(128, 50, img_gray.shape).astype(np.uint8)\n",
        "    target_img = np.clip(target_img, 0, 255)\n",
        "\n",
        "# Resize target to match source size\n",
        "if target_img.shape != img_gray.shape:\n",
        "    target_img = cv2.resize(target_img, (img_gray.shape[1], img_gray.shape[0]))\n",
        "\n",
        "# Perform histogram matching\n",
        "matched = exposure.match_histograms(img_gray, target_img, channel_axis=None)\n",
        "\n",
        "# Calculate histograms\n",
        "hist_source = cv2.calcHist([img_gray], [0], None, [256], [0, 256])\n",
        "hist_target = cv2.calcHist([target_img], [0], None, [256], [0, 256])\n",
        "hist_matched = cv2.calcHist([matched.astype(np.uint8)], [0], None, [256], [0, 256])\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(12, 15))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Source Image')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(target_img, cmap='gray')\n",
        "axes[0,1].set_title('Target Image')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(matched, cmap='gray')\n",
        "axes[1,0].set_title('Matched Image')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].plot(hist_source, color='blue', label='Source')\n",
        "axes[1,1].plot(hist_target, color='red', label='Target', alpha=0.7)\n",
        "axes[1,1].set_xlabel('Pixel Intensity')\n",
        "axes[1,1].set_ylabel('Frequency')\n",
        "axes[1,1].set_title('Source vs Target Histogram')\n",
        "axes[1,1].legend()\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2,0].plot(hist_matched, color='green', label='Matched')\n",
        "axes[2,0].plot(hist_target, color='red', label='Target', alpha=0.7)\n",
        "axes[2,0].set_xlabel('Pixel Intensity')\n",
        "axes[2,0].set_ylabel('Frequency')\n",
        "axes[2,0].set_title('Matched vs Target Histogram')\n",
        "axes[2,0].legend()\n",
        "axes[2,0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Operasi Morfologi\n",
        "\n",
        "Operasi morfologi adalah operasi berbasis struktur yang bekerja pada bentuk dan struktur objek dalam citra biner.\n",
        "\n",
        "## 1. Dilation (Dilasi) dan Erosion (Erosi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Morphological operations - Dilation and Erosion\n",
        "# Create binary image for demonstration\n",
        "_, binary_img = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Define structuring element\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "# Erosion\n",
        "erosion = cv2.erode(binary_img, kernel, iterations=1)\n",
        "\n",
        "# Dilation\n",
        "dilation = cv2.dilate(binary_img, kernel, iterations=1)\n",
        "\n",
        "# Different kernel shapes\n",
        "kernel_cross = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))\n",
        "kernel_ellipse = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "\n",
        "erosion_cross = cv2.erode(binary_img, kernel_cross, iterations=1)\n",
        "dilation_ellipse = cv2.dilate(binary_img, kernel_ellipse, iterations=1)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(binary_img, cmap='gray')\n",
        "axes[0,0].set_title('Original Binary')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(erosion, cmap='gray')\n",
        "axes[0,1].set_title('Erosion (Rectangular)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(dilation, cmap='gray')\n",
        "axes[0,2].set_title('Dilation (Rectangular)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(binary_img, cmap='gray')\n",
        "axes[1,0].set_title('Original Binary')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(erosion_cross, cmap='gray')\n",
        "axes[1,1].set_title('Erosion (Cross)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(dilation_ellipse, cmap='gray')\n",
        "axes[1,2].set_title('Dilation (Ellipse)')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Opening dan Closing\n",
        "\n",
        "**Opening** = Erosion diikuti Dilation (menghilangkan noise kecil, memisahkan objek)\n",
        "**Closing** = Dilation diikuti Erosion (menutup lubang kecil, menyambungkan objek)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Opening and Closing\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "# Opening\n",
        "opening = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "# Closing\n",
        "closing = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# Multiple iterations\n",
        "opening_2 = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "closing_2 = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(binary_img, cmap='gray')\n",
        "axes[0,0].set_title('Original Binary')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(opening, cmap='gray')\n",
        "axes[0,1].set_title('Opening (1 iteration)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(closing, cmap='gray')\n",
        "axes[0,2].set_title('Closing (1 iteration)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(binary_img, cmap='gray')\n",
        "axes[1,0].set_title('Original Binary')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(opening_2, cmap='gray')\n",
        "axes[1,1].set_title('Opening (2 iterations)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(closing_2, cmap='gray')\n",
        "axes[1,2].set_title('Closing (2 iterations)')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hit-Miss Operator\n",
        "\n",
        "Hit-Miss operator digunakan untuk deteksi pola spesifik dalam citra biner.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hit-Miss Operator\n",
        "# Create a simple pattern to detect\n",
        "kernel_hitmiss = np.array([[-1, -1, -1],\n",
        "                           [ 1,  1,  1],\n",
        "                           [-1, -1, -1]], dtype=np.int8)\n",
        "\n",
        "hitmiss = cv2.morphologyEx(binary_img, cv2.MORPH_HITMISS, kernel_hitmiss)\n",
        "\n",
        "# Alternative: using separate hit and miss kernels\n",
        "kernel_hit = np.array([[0, 0, 0],\n",
        "                       [1, 1, 1],\n",
        "                       [0, 0, 0]], dtype=np.uint8)\n",
        "\n",
        "kernel_miss = np.array([[1, 1, 1],\n",
        "                        [0, 0, 0],\n",
        "                        [1, 1, 1]], dtype=np.uint8)\n",
        "\n",
        "# Manual hit-miss\n",
        "hit = cv2.morphologyEx(binary_img, cv2.MORPH_ERODE, kernel_hit)\n",
        "miss = cv2.morphologyEx(255 - binary_img, cv2.MORPH_ERODE, kernel_miss)\n",
        "hitmiss_manual = cv2.bitwise_and(hit, miss)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes[0,0].imshow(binary_img, cmap='gray')\n",
        "axes[0,0].set_title('Original Binary')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(hitmiss, cmap='gray')\n",
        "axes[0,1].set_title('Hit-Miss (OpenCV)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(hit, cmap='gray')\n",
        "axes[1,0].set_title('Hit Component')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(hitmiss_manual, cmap='gray')\n",
        "axes[1,1].set_title('Hit-Miss (Manual)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. Konvolusi dan Filtering\n",
        "\n",
        "Konvolusi adalah operasi fundamental dalam pengolahan citra untuk filtering, edge detection, dan feature extraction.\n",
        "\n",
        "## 1. Konvolusi dan Filtering Dasar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convolution and Filtering\n",
        "# Define various kernels\n",
        "# Identity kernel\n",
        "kernel_identity = np.array([[0, 0, 0],\n",
        "                            [0, 1, 0],\n",
        "                            [0, 0, 0]])\n",
        "\n",
        "# Box filter (averaging)\n",
        "kernel_box = np.ones((5, 5)) / 25\n",
        "\n",
        "# Custom kernel\n",
        "kernel_custom = np.array([[-1, -1, -1],\n",
        "                          [-1,  8, -1],\n",
        "                          [-1, -1, -1]])\n",
        "\n",
        "# Apply convolution\n",
        "identity_result = cv2.filter2D(img_gray, -1, kernel_identity)\n",
        "box_result = cv2.filter2D(img_gray, -1, kernel_box)\n",
        "custom_result = cv2.filter2D(img_gray, -1, kernel_custom)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(identity_result, cmap='gray')\n",
        "axes[0,1].set_title('Identity Kernel')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(box_result, cmap='gray')\n",
        "axes[1,0].set_title('Box Filter (Averaging)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(custom_result, cmap='gray')\n",
        "axes[1,1].set_title('Custom Kernel (Sharpening)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Smoothing dengan Gaussian Convolution\n",
        "\n",
        "Gaussian filter adalah filter smoothing yang efektif untuk mengurangi noise sambil mempertahankan edge.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gaussian Smoothing\n",
        "# Different sigma values\n",
        "gaussian_1 = cv2.GaussianBlur(img_gray, (5, 5), 1.0)\n",
        "gaussian_2 = cv2.GaussianBlur(img_gray, (5, 5), 2.0)\n",
        "gaussian_3 = cv2.GaussianBlur(img_gray, (9, 9), 3.0)\n",
        "\n",
        "# Create Gaussian kernel manually\n",
        "def create_gaussian_kernel(size, sigma):\n",
        "    kernel = np.zeros((size, size))\n",
        "    center = size // 2\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            x, y = i - center, j - center\n",
        "            kernel[i, j] = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
        "    kernel = kernel / np.sum(kernel)\n",
        "    return kernel\n",
        "\n",
        "gaussian_kernel = create_gaussian_kernel(5, 1.0)\n",
        "gaussian_manual = cv2.filter2D(img_gray, -1, gaussian_kernel)\n",
        "\n",
        "# Integral Image (for fast box filtering)\n",
        "# Note: OpenCV doesn't have direct integral image filtering, but we can demonstrate the concept\n",
        "integral_img = cv2.integral(img_gray)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(gaussian_1, cmap='gray')\n",
        "axes[0,1].set_title('Gaussian (σ=1.0)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(gaussian_2, cmap='gray')\n",
        "axes[0,2].set_title('Gaussian (σ=2.0)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(gaussian_3, cmap='gray')\n",
        "axes[1,0].set_title('Gaussian (σ=3.0, 9x9)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(gaussian_manual, cmap='gray')\n",
        "axes[1,1].set_title('Gaussian (Manual Kernel)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(integral_img, cmap='gray')\n",
        "axes[1,2].set_title('Integral Image')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize Gaussian kernel\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(gaussian_kernel, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.title('Gaussian Kernel (5x5, σ=1.0)')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Turunan Pertama: Image Gradient\n",
        "\n",
        "Gradient citra menunjukkan perubahan intensitas, berguna untuk edge detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First Derivative: Image Gradient\n",
        "# Sobel operators\n",
        "sobel_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "sobel_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "# Convert to absolute values and scale\n",
        "sobel_x = np.absolute(sobel_x)\n",
        "sobel_y = np.absolute(sobel_y)\n",
        "sobel_x = np.uint8(255 * sobel_x / np.max(sobel_x))\n",
        "sobel_y = np.uint8(255 * sobel_y / np.max(sobel_y))\n",
        "\n",
        "# Gradient magnitude\n",
        "sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "sobel_magnitude = np.uint8(255 * sobel_magnitude / np.max(sobel_magnitude))\n",
        "\n",
        "# Gradient direction\n",
        "sobel_direction = np.arctan2(sobel_y.astype(float), sobel_x.astype(float))\n",
        "\n",
        "# Prewitt operators\n",
        "kernel_prewitt_x = np.array([[-1, 0, 1],\n",
        "                              [-1, 0, 1],\n",
        "                              [-1, 0, 1]])\n",
        "kernel_prewitt_y = np.array([[-1, -1, -1],\n",
        "                              [ 0,  0,  0],\n",
        "                              [ 1,  1,  1]])\n",
        "\n",
        "prewitt_x = cv2.filter2D(img_gray, cv2.CV_64F, kernel_prewitt_x)\n",
        "prewitt_y = cv2.filter2D(img_gray, cv2.CV_64F, kernel_prewitt_y)\n",
        "prewitt_x = np.absolute(prewitt_x)\n",
        "prewitt_y = np.absolute(prewitt_y)\n",
        "prewitt_x = np.uint8(255 * prewitt_x / np.max(prewitt_x))\n",
        "prewitt_y = np.uint8(255 * prewitt_y / np.max(prewitt_y))\n",
        "prewitt_magnitude = np.sqrt(prewitt_x**2 + prewitt_y**2)\n",
        "prewitt_magnitude = np.uint8(255 * prewitt_magnitude / np.max(prewitt_magnitude))\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(sobel_x, cmap='gray')\n",
        "axes[0,1].set_title('Sobel X')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(sobel_y, cmap='gray')\n",
        "axes[0,2].set_title('Sobel Y')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(sobel_magnitude, cmap='gray')\n",
        "axes[1,0].set_title('Sobel Magnitude')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(sobel_direction, cmap='hsv')\n",
        "axes[1,1].set_title('Sobel Direction')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(prewitt_x, cmap='gray')\n",
        "axes[1,2].set_title('Prewitt X')\n",
        "axes[1,2].axis('off')\n",
        "\n",
        "axes[2,0].imshow(prewitt_y, cmap='gray')\n",
        "axes[2,0].set_title('Prewitt Y')\n",
        "axes[2,0].axis('off')\n",
        "\n",
        "axes[2,1].imshow(prewitt_magnitude, cmap='gray')\n",
        "axes[2,1].set_title('Prewitt Magnitude')\n",
        "axes[2,1].axis('off')\n",
        "\n",
        "axes[2,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Turunan Kedua: Laplacian of Gaussian (LoG) dan Difference of Gaussian (DoG)\n",
        "\n",
        "Turunan kedua digunakan untuk deteksi zero-crossing pada edge.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Second Derivative: Laplacian of Gaussian (LoG) and Difference of Gaussian (DoG)\n",
        "# Laplacian\n",
        "laplacian = cv2.Laplacian(img_gray, cv2.CV_64F)\n",
        "laplacian = np.absolute(laplacian)\n",
        "laplacian = np.uint8(255 * laplacian / np.max(laplacian))\n",
        "\n",
        "# LoG (Laplacian of Gaussian)\n",
        "# Method 1: Gaussian blur then Laplacian\n",
        "gaussian_for_log = cv2.GaussianBlur(img_gray, (5, 5), 1.0)\n",
        "log_1 = cv2.Laplacian(gaussian_for_log, cv2.CV_64F)\n",
        "log_1 = np.absolute(log_1)\n",
        "log_1 = np.uint8(255 * log_1 / np.max(log_1))\n",
        "\n",
        "# Method 2: Using LoG kernel directly\n",
        "def create_log_kernel(size, sigma):\n",
        "    kernel = np.zeros((size, size))\n",
        "    center = size // 2\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            x, y = i - center, j - center\n",
        "            r_squared = x**2 + y**2\n",
        "            kernel[i, j] = ((r_squared - 2 * sigma**2) / (sigma**4)) * \\\n",
        "                          np.exp(-r_squared / (2 * sigma**2))\n",
        "    return kernel\n",
        "\n",
        "log_kernel = create_log_kernel(9, 1.5)\n",
        "log_2 = cv2.filter2D(img_gray, cv2.CV_64F, log_kernel)\n",
        "log_2 = np.absolute(log_2)\n",
        "log_2 = np.uint8(255 * log_2 / np.max(log_2))\n",
        "\n",
        "# DoG (Difference of Gaussian)\n",
        "gaussian_small = cv2.GaussianBlur(img_gray, (5, 5), 1.0)\n",
        "gaussian_large = cv2.GaussianBlur(img_gray, (5, 5), 2.0)\n",
        "dog = gaussian_small.astype(float) - gaussian_large.astype(float)\n",
        "dog = np.absolute(dog)\n",
        "dog = np.uint8(255 * dog / np.max(dog))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(laplacian, cmap='gray')\n",
        "axes[0,1].set_title('Laplacian')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(log_1, cmap='gray')\n",
        "axes[0,2].set_title('LoG (Gaussian + Laplacian)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(log_2, cmap='gray')\n",
        "axes[1,0].set_title('LoG (Direct Kernel)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(dog, cmap='gray')\n",
        "axes[1,1].set_title('DoG (Difference of Gaussian)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(log_kernel, cmap='hot', interpolation='nearest')\n",
        "axes[1,2].set_title('LoG Kernel')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Nonlinear Filters\n",
        "\n",
        "Filter nonlinier lebih efektif untuk menghilangkan noise sambil mempertahankan edge dibanding filter linier.\n",
        "\n",
        "### Median Filter\n",
        "### Mean-shift Filter\n",
        "### Bilateral Filter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nonlinear Filters\n",
        "# Add some noise for demonstration\n",
        "noise = np.random.normal(0, 25, img_gray.shape).astype(np.int16)\n",
        "img_noisy = np.clip(img_gray.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Median Filter\n",
        "median_3 = cv2.medianBlur(img_noisy, 3)\n",
        "median_5 = cv2.medianBlur(img_noisy, 5)\n",
        "\n",
        "# Bilateral Filter (edge-preserving smoothing)\n",
        "bilateral = cv2.bilateralFilter(img_noisy, 9, 75, 75)\n",
        "\n",
        "# Mean-shift Filter (using scipy)\n",
        "try:\n",
        "    from scipy.ndimage import uniform_filter\n",
        "    mean_shift_approx = uniform_filter(img_noisy, size=5)\n",
        "except:\n",
        "    mean_shift_approx = cv2.blur(img_noisy, (5, 5))\n",
        "\n",
        "# Comparison with Gaussian (linear filter)\n",
        "gaussian_comparison = cv2.GaussianBlur(img_noisy, (5, 5), 1.5)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original (No Noise)')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(img_noisy, cmap='gray')\n",
        "axes[0,1].set_title('Noisy Image')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(median_5, cmap='gray')\n",
        "axes[0,2].set_title('Median Filter (5x5)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(bilateral, cmap='gray')\n",
        "axes[1,0].set_title('Bilateral Filter')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(gaussian_comparison, cmap='gray')\n",
        "axes[1,1].set_title('Gaussian Filter (Linear)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(mean_shift_approx, cmap='gray')\n",
        "axes[1,2].set_title('Mean-shift Approximation')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Edge preservation comparison\n",
        "edge_original = cv2.Canny(img_gray, 50, 150)\n",
        "edge_gaussian = cv2.Canny(gaussian_comparison, 50, 150)\n",
        "edge_bilateral = cv2.Canny(bilateral, 50, 150)\n",
        "edge_median = cv2.Canny(median_5, 50, 150)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes[0,0].imshow(edge_original, cmap='gray')\n",
        "axes[0,0].set_title('Edges: Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(edge_gaussian, cmap='gray')\n",
        "axes[0,1].set_title('Edges: Gaussian (blurred)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(edge_bilateral, cmap='gray')\n",
        "axes[1,0].set_title('Edges: Bilateral (preserved)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(edge_median, cmap='gray')\n",
        "axes[1,1].set_title('Edges: Median (preserved)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11. Transformasi Domain Frekuensi\n",
        "\n",
        "Transformasi domain frekuensi memungkinkan analisis dan manipulasi citra dalam domain frekuensi.\n",
        "\n",
        "## 1. Fourier Transform\n",
        "\n",
        "Fourier Transform mengkonversi citra dari domain spasial ke domain frekuensi.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fourier Transform\n",
        "from scipy.fft import fft2, fftshift, ifft2, ifftshift\n",
        "\n",
        "# Compute 2D FFT\n",
        "f_transform = fft2(img_gray)\n",
        "f_shift = fftshift(f_transform)\n",
        "\n",
        "# Magnitude spectrum\n",
        "magnitude_spectrum = np.log(np.abs(f_shift) + 1)\n",
        "\n",
        "# Phase spectrum\n",
        "phase_spectrum = np.angle(f_shift)\n",
        "\n",
        "# Reconstruct from magnitude only\n",
        "magnitude_only = np.abs(f_shift)\n",
        "reconstructed_magnitude = np.abs(ifft2(ifftshift(magnitude_only)))\n",
        "\n",
        "# Reconstruct from phase only\n",
        "phase_only = np.exp(1j * phase_spectrum)\n",
        "reconstructed_phase = np.abs(ifft2(ifftshift(phase_only)))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original Image')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(magnitude_spectrum, cmap='gray')\n",
        "axes[0,1].set_title('Magnitude Spectrum (log scale)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(phase_spectrum, cmap='gray')\n",
        "axes[0,2].set_title('Phase Spectrum')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(img_gray, cmap='gray')\n",
        "axes[1,0].set_title('Original')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(reconstructed_magnitude, cmap='gray')\n",
        "axes[1,1].set_title('Reconstructed (Magnitude Only)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(reconstructed_phase, cmap='gray')\n",
        "axes[1,2].set_title('Reconstructed (Phase Only)')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Discrete Fourier Transform (DFT)\n",
        "\n",
        "DFT adalah implementasi diskrit dari Fourier Transform untuk citra digital.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discrete Fourier Transform using OpenCV\n",
        "dft = cv2.dft(np.float32(img_gray), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
        "dft_shift = np.fft.fftshift(dft)\n",
        "\n",
        "magnitude_spectrum_cv = 20 * np.log(cv2.magnitude(dft_shift[:,:,0], dft_shift[:,:,1]) + 1)\n",
        "\n",
        "# Inverse DFT\n",
        "dft_ishift = np.fft.ifftshift(dft_shift)\n",
        "img_back = cv2.idft(dft_ishift)\n",
        "img_back = cv2.magnitude(img_back[:,:,0], img_back[:,:,1])\n",
        "\n",
        "# Compare original and reconstructed\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(img_gray, cmap='gray')\n",
        "axes[0].set_title('Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(magnitude_spectrum_cv, cmap='gray')\n",
        "axes[1].set_title('DFT Magnitude Spectrum (OpenCV)')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(img_back, cmap='gray')\n",
        "axes[2].set_title('Reconstructed (Inverse DFT)')\n",
        "axes[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Reconstruction error: {np.mean(np.abs(img_gray.astype(float) - img_back)):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Frequency Domain Filtering\n",
        "\n",
        "Filtering dalam domain frekuensi: Highpass, Lowpass, Bandpass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frequency Domain Filtering\n",
        "rows, cols = img_gray.shape\n",
        "crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "# Create masks\n",
        "def create_lowpass_mask(rows, cols, radius):\n",
        "    mask = np.zeros((rows, cols), np.uint8)\n",
        "    center = (rows//2, cols//2)\n",
        "    y, x = np.ogrid[:rows, :cols]\n",
        "    mask_area = (x - center[1])**2 + (y - center[0])**2 <= radius**2\n",
        "    mask[mask_area] = 1\n",
        "    return mask\n",
        "\n",
        "def create_highpass_mask(rows, cols, radius):\n",
        "    return 1 - create_lowpass_mask(rows, cols, radius)\n",
        "\n",
        "def create_bandpass_mask(rows, cols, inner_radius, outer_radius):\n",
        "    mask = np.zeros((rows, cols), np.uint8)\n",
        "    center = (rows//2, cols//2)\n",
        "    y, x = np.ogrid[:rows, :cols]\n",
        "    mask_area = ((x - center[1])**2 + (y - center[0])**2 >= inner_radius**2) & \\\n",
        "                ((x - center[1])**2 + (y - center[0])**2 <= outer_radius**2)\n",
        "    mask[mask_area] = 1\n",
        "    return mask\n",
        "\n",
        "# Apply filters\n",
        "f_transform = fft2(img_gray)\n",
        "f_shift = fftshift(f_transform)\n",
        "\n",
        "# Lowpass filter\n",
        "lowpass_mask = create_lowpass_mask(rows, cols, 50)\n",
        "f_shift_low = f_shift * lowpass_mask\n",
        "f_ishift_low = ifftshift(f_shift_low)\n",
        "img_lowpass = np.abs(ifft2(f_ishift_low))\n",
        "\n",
        "# Highpass filter\n",
        "highpass_mask = create_highpass_mask(rows, cols, 30)\n",
        "f_shift_high = f_shift * highpass_mask\n",
        "f_ishift_high = ifftshift(f_shift_high)\n",
        "img_highpass = np.abs(ifft2(f_ishift_high))\n",
        "\n",
        "# Bandpass filter\n",
        "bandpass_mask = create_bandpass_mask(rows, cols, 20, 60)\n",
        "f_shift_band = f_shift * bandpass_mask\n",
        "f_ishift_band = ifftshift(f_shift_band)\n",
        "img_bandpass = np.abs(ifft2(f_ishift_band))\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(lowpass_mask, cmap='gray')\n",
        "axes[0,1].set_title('Lowpass Mask')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(img_lowpass, cmap='gray')\n",
        "axes[0,2].set_title('Lowpass Filtered')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(img_gray, cmap='gray')\n",
        "axes[1,0].set_title('Original')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(highpass_mask, cmap='gray')\n",
        "axes[1,1].set_title('Highpass Mask')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(img_highpass, cmap='gray')\n",
        "axes[1,2].set_title('Highpass Filtered')\n",
        "axes[1,2].axis('off')\n",
        "\n",
        "axes[2,0].imshow(img_gray, cmap='gray')\n",
        "axes[2,0].set_title('Original')\n",
        "axes[2,0].axis('off')\n",
        "\n",
        "axes[2,1].imshow(bandpass_mask, cmap='gray')\n",
        "axes[2,1].set_title('Bandpass Mask')\n",
        "axes[2,1].axis('off')\n",
        "\n",
        "axes[2,2].imshow(img_bandpass, cmap='gray')\n",
        "axes[2,2].set_title('Bandpass Filtered')\n",
        "axes[2,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Discrete Wavelet Transform (DWT)\n",
        "\n",
        "Wavelet Transform memberikan representasi multi-resolution dari citra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discrete Wavelet Transform\n",
        "try:\n",
        "    import pywt\n",
        "    \n",
        "    # Perform 2D DWT\n",
        "    coeffs = pywt.dwt2(img_gray, 'haar')\n",
        "    cA, (cH, cV, cD) = coeffs\n",
        "    \n",
        "    # Visualize coefficients\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "    axes[0,0].imshow(cA, cmap='gray')\n",
        "    axes[0,0].set_title('Approximation (cA)')\n",
        "    axes[0,0].axis('off')\n",
        "    \n",
        "    axes[0,1].imshow(cH, cmap='gray')\n",
        "    axes[0,1].set_title('Horizontal Detail (cH)')\n",
        "    axes[0,1].axis('off')\n",
        "    \n",
        "    axes[1,0].imshow(cV, cmap='gray')\n",
        "    axes[1,0].set_title('Vertical Detail (cV)')\n",
        "    axes[1,0].axis('off')\n",
        "    \n",
        "    axes[1,1].imshow(cD, cmap='gray')\n",
        "    axes[1,1].set_title('Diagonal Detail (cD)')\n",
        "    axes[1,1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Reconstruct image\n",
        "    img_reconstructed = pywt.idwt2(coeffs, 'haar')\n",
        "    \n",
        "    # Multi-level decomposition\n",
        "    coeffs2 = pywt.wavedec2(img_gray, 'haar', level=2)\n",
        "    cA2 = coeffs2[0]\n",
        "    details2 = coeffs2[1:]\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].imshow(img_gray, cmap='gray')\n",
        "    axes[0].set_title('Original')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(img_reconstructed, cmap='gray')\n",
        "    axes[1].set_title('Reconstructed from DWT')\n",
        "    axes[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Reconstruction error: {np.mean(np.abs(img_gray.astype(float) - img_reconstructed)):.2f}\")\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"PyWavelets not installed. Installing...\")\n",
        "    print(\"Please run: pip install PyWavelets\")\n",
        "    # Create a simple approximation\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.text(0.5, 0.5, 'PyWavelets library required\\nfor DWT demonstration', \n",
        "            ha='center', va='center', fontsize=14)\n",
        "    ax.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12. Pyramids, Edge Detection, dan Feature Detection/Description\n",
        "\n",
        "## 1. Gaussian Pyramid\n",
        "\n",
        "Gaussian Pyramid adalah representasi multi-scale dari citra menggunakan downsampling berulang.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gaussian Pyramid\n",
        "def build_gaussian_pyramid(img, levels=4):\n",
        "    pyramid = [img]\n",
        "    current = img.copy()\n",
        "    for i in range(levels-1):\n",
        "        current = cv2.pyrDown(current)\n",
        "        pyramid.append(current)\n",
        "    return pyramid\n",
        "\n",
        "gaussian_pyramid = build_gaussian_pyramid(img_gray, levels=4)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "for i, level in enumerate(gaussian_pyramid):\n",
        "    axes[i].imshow(level, cmap='gray')\n",
        "    axes[i].set_title(f'Level {i} ({level.shape[1]}x{level.shape[0]})')\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Laplacian Pyramid\n",
        "\n",
        "Laplacian Pyramid menyimpan perbedaan antara level-level Gaussian Pyramid, berguna untuk kompresi dan blending.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Laplacian Pyramid\n",
        "def build_laplacian_pyramid(img, levels=4):\n",
        "    gaussian_pyr = build_gaussian_pyramid(img, levels)\n",
        "    laplacian_pyr = []\n",
        "    \n",
        "    for i in range(levels-1):\n",
        "        size = (gaussian_pyr[i].shape[1], gaussian_pyr[i].shape[0])\n",
        "        gaussian_expanded = cv2.pyrUp(gaussian_pyr[i+1], dstsize=size)\n",
        "        laplacian = cv2.subtract(gaussian_pyr[i], gaussian_expanded)\n",
        "        laplacian_pyr.append(laplacian)\n",
        "    \n",
        "    laplacian_pyr.append(gaussian_pyr[-1])  # Top level is the same\n",
        "    return laplacian_pyr, gaussian_pyr\n",
        "\n",
        "laplacian_pyramid, gaussian_pyramid = build_laplacian_pyramid(img_gray, levels=4)\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "for i in range(4):\n",
        "    axes[0,i].imshow(gaussian_pyramid[i], cmap='gray')\n",
        "    axes[0,i].set_title(f'Gaussian Level {i}')\n",
        "    axes[0,i].axis('off')\n",
        "    \n",
        "    # Normalize Laplacian for display\n",
        "    lap_display = laplacian_pyramid[i].copy()\n",
        "    if lap_display.min() < 0:\n",
        "        lap_display = lap_display - lap_display.min()\n",
        "    if lap_display.max() > 0:\n",
        "        lap_display = (lap_display / lap_display.max() * 255).astype(np.uint8)\n",
        "    \n",
        "    axes[1,i].imshow(lap_display, cmap='gray')\n",
        "    axes[1,i].set_title(f'Laplacian Level {i}')\n",
        "    axes[1,i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Canny Edge Detector\n",
        "\n",
        "Canny edge detector adalah algoritma edge detection yang populer dengan deteksi edge yang baik.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Canny Edge Detector\n",
        "# Different threshold combinations\n",
        "edges_canny1 = cv2.Canny(img_gray, 50, 150)\n",
        "edges_canny2 = cv2.Canny(img_gray, 100, 200)\n",
        "edges_canny3 = cv2.Canny(img_gray, 50, 100)\n",
        "edges_canny4 = cv2.Canny(img_gray, 150, 250)\n",
        "\n",
        "# With Gaussian blur preprocessing\n",
        "img_blurred = cv2.GaussianBlur(img_gray, (5, 5), 1.0)\n",
        "edges_canny_blur = cv2.Canny(img_blurred, 50, 150)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(edges_canny1, cmap='gray')\n",
        "axes[0,1].set_title('Canny (50, 150)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(edges_canny2, cmap='gray')\n",
        "axes[0,2].set_title('Canny (100, 200)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(edges_canny3, cmap='gray')\n",
        "axes[1,0].set_title('Canny (50, 100) - More edges')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(edges_canny4, cmap='gray')\n",
        "axes[1,1].set_title('Canny (150, 250) - Fewer edges')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(edges_canny_blur, cmap='gray')\n",
        "axes[1,2].set_title('Canny (with Gaussian blur)')\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Detector: Harris Corner Detector dan SIFT\n",
        "\n",
        "Feature detector mengidentifikasi titik-titik menarik dalam citra (corners, keypoints).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Detectors\n",
        "# Harris Corner Detector\n",
        "harris = cv2.cornerHarris(img_gray, 2, 3, 0.04)\n",
        "harris = cv2.dilate(harris, None)\n",
        "img_harris = img_rgb.copy()\n",
        "img_harris[harris > 0.01 * harris.max()] = [255, 0, 0]  # Mark corners in red\n",
        "\n",
        "# Good Features to Track (improved corner detection)\n",
        "corners = cv2.goodFeaturesToTrack(img_gray, maxCorners=100, qualityLevel=0.01, minDistance=10)\n",
        "img_corners = img_rgb.copy()\n",
        "if corners is not None:\n",
        "    corners = np.int0(corners)\n",
        "    for i in corners:\n",
        "        x, y = i.ravel()\n",
        "        cv2.circle(img_corners, (x, y), 3, (0, 255, 0), -1)\n",
        "\n",
        "# SIFT Feature Detector\n",
        "try:\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints_sift, descriptors_sift = sift.detectAndCompute(img_gray, None)\n",
        "    img_sift = cv2.drawKeypoints(img_rgb, keypoints_sift, None, \n",
        "                                 flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "except:\n",
        "    img_sift = img_rgb.copy()\n",
        "    keypoints_sift = []\n",
        "    print(\"SIFT not available (requires opencv-contrib-python)\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(img_harris)\n",
        "axes[0,1].set_title('Harris Corner Detector')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(img_corners)\n",
        "axes[1,0].set_title('Good Features to Track')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(img_sift)\n",
        "axes[1,1].set_title(f'SIFT Keypoints ({len(keypoints_sift)})')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Descriptor: SIFT Feature Descriptor, Shape Context, HOG\n",
        "\n",
        "Feature descriptor mengkarakterisasi region sekitar keypoint untuk matching dan recognition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Descriptors\n",
        "# SIFT Descriptor (already computed above, but let's visualize it)\n",
        "if len(keypoints_sift) > 0:\n",
        "    print(f\"SIFT Descriptors shape: {descriptors_sift.shape}\")\n",
        "    print(f\"Number of keypoints: {len(keypoints_sift)}\")\n",
        "    print(f\"Descriptor dimension: {descriptors_sift.shape[1]}\")\n",
        "    \n",
        "    # Visualize descriptor for one keypoint\n",
        "    if descriptors_sift.shape[0] > 0:\n",
        "        sample_descriptor = descriptors_sift[0]\n",
        "        plt.figure(figsize=(12, 3))\n",
        "        plt.bar(range(len(sample_descriptor)), sample_descriptor)\n",
        "        plt.title('SIFT Descriptor (First Keypoint)')\n",
        "        plt.xlabel('Descriptor Index')\n",
        "        plt.ylabel('Value')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# HOG (Histogram of Oriented Gradients)\n",
        "try:\n",
        "    from skimage.feature import hog\n",
        "    from skimage import exposure as skexposure\n",
        "    \n",
        "    # Compute HOG features\n",
        "    hog_features, hog_image = hog(img_gray, orientations=9, pixels_per_cell=(8, 8),\n",
        "                                  cells_per_block=(2, 2), visualize=True, feature_vector=True)\n",
        "    \n",
        "    # Rescale histogram for better visualization\n",
        "    hog_image_rescaled = skexposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axes[0].imshow(img_gray, cmap='gray')\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(hog_image_rescaled, cmap='gray')\n",
        "    axes[1].set_title('HOG Visualization')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    axes[2].bar(range(len(hog_features[:100])), hog_features[:100])\n",
        "    axes[2].set_title('HOG Features (First 100)')\n",
        "    axes[2].set_xlabel('Feature Index')\n",
        "    axes[2].set_ylabel('Value')\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"HOG Features shape: {hog_features.shape}\")\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"scikit-image required for HOG. Using alternative method...\")\n",
        "    # Simple gradient-based descriptor\n",
        "    sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
        "    angle = np.arctan2(sobely, sobelx)\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(magnitude, cmap='gray')\n",
        "    plt.title('Gradient Magnitude')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(angle, cmap='hsv')\n",
        "    plt.title('Gradient Direction')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ORB Descriptor (alternative to SIFT, faster)\n",
        "orb = cv2.ORB_create(nfeatures=100)\n",
        "keypoints_orb, descriptors_orb = orb.detectAndCompute(img_gray, None)\n",
        "img_orb = cv2.drawKeypoints(img_rgb, keypoints_orb, None, color=(0, 255, 0), flags=0)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title('Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_orb)\n",
        "axes[1].set_title(f'ORB Keypoints ({len(keypoints_orb)})')\n",
        "axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if descriptors_orb is not None:\n",
        "    print(f\"ORB Descriptors shape: {descriptors_orb.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13. Pengolahan Citra Berwarna\n",
        "\n",
        "## 1. Trichromacy\n",
        "\n",
        "Trichromacy adalah teori bahwa penglihatan warna manusia didasarkan pada tiga jenis sel kerucut (cones) yang sensitif terhadap panjang gelombang berbeda.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trichromacy - Color Vision\n",
        "# Simulate cone responses (simplified)\n",
        "def simulate_cone_response(wavelength):\n",
        "    \"\"\"Simulate S, M, L cone responses\"\"\"\n",
        "    # S-cone (short wavelength, blue)\n",
        "    s_response = np.exp(-((wavelength - 420)**2) / (2 * 30**2))\n",
        "    # M-cone (medium wavelength, green)\n",
        "    m_response = np.exp(-((wavelength - 530)**2) / (2 * 30**2))\n",
        "    # L-cone (long wavelength, red)\n",
        "    l_response = np.exp(-((wavelength - 560)**2) / (2 * 30**2))\n",
        "    return s_response, m_response, l_response\n",
        "\n",
        "wavelengths = np.linspace(400, 700, 300)\n",
        "s_responses, m_responses, l_responses = [], [], []\n",
        "\n",
        "for w in wavelengths:\n",
        "    s, m, l = simulate_cone_response(w)\n",
        "    s_responses.append(s)\n",
        "    m_responses.append(m)\n",
        "    l_responses.append(l)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(wavelengths, s_responses, 'b', label='S-cone (Blue)', linewidth=2)\n",
        "ax.plot(wavelengths, m_responses, 'g', label='M-cone (Green)', linewidth=2)\n",
        "ax.plot(wavelengths, l_responses, 'r', label='L-cone (Red)', linewidth=2)\n",
        "ax.set_xlabel('Wavelength (nm)')\n",
        "ax.set_ylabel('Normalized Response')\n",
        "ax.set_title('Trichromatic Cone Response Functions')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Demonstrate RGB separation (trichromacy in digital imaging)\n",
        "img_color = cv2.imread(\"images/mandrill.jpg\", cv2.IMREAD_COLOR)\n",
        "img_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Split into R, G, B channels\n",
        "r, g, b = cv2.split(img_rgb)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title('Original RGB Image')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(r, cmap='Reds')\n",
        "axes[0,1].set_title('Red Channel (L-cone response)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(g, cmap='Greens')\n",
        "axes[1,0].set_title('Green Channel (M-cone response)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(b, cmap='Blues')\n",
        "axes[1,1].set_title('Blue Channel (S-cone response)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Linear Color Transformation\n",
        "\n",
        "Transformasi warna linier digunakan untuk konversi antar color space dan manipulasi warna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear Color Transformation\n",
        "# RGB to Grayscale (linear combination)\n",
        "gray_linear = 0.299 * r.astype(float) + 0.587 * g.astype(float) + 0.114 * b.astype(float)\n",
        "gray_linear = gray_linear.astype(np.uint8)\n",
        "\n",
        "# Brightness adjustment (linear)\n",
        "brightness_factor = 1.3\n",
        "img_bright = np.clip(img_rgb.astype(float) * brightness_factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Contrast adjustment (linear)\n",
        "contrast_factor = 1.5\n",
        "img_contrast = np.clip((img_rgb.astype(float) - 128) * contrast_factor + 128, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Color matrix transformation\n",
        "# Example: Sepia tone\n",
        "sepia_matrix = np.array([[0.393, 0.769, 0.189],\n",
        "                         [0.349, 0.686, 0.168],\n",
        "                         [0.272, 0.534, 0.131]])\n",
        "img_sepia = cv2.transform(img_rgb, sepia_matrix)\n",
        "img_sepia = np.clip(img_sepia, 0, 255).astype(np.uint8)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(img_bright)\n",
        "axes[0,1].set_title('Brightness Adjusted (×1.3)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(img_contrast)\n",
        "axes[1,0].set_title('Contrast Adjusted (×1.5)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(img_sepia)\n",
        "axes[1,1].set_title('Sepia Tone (Linear Transform)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Color Spaces\n",
        "\n",
        "Berbagai color space memiliki keunggulan berbeda untuk aplikasi tertentu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Color Spaces\n",
        "# RGB (already have)\n",
        "img_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# HSV (Hue, Saturation, Value)\n",
        "img_hsv = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV)\n",
        "h, s, v = cv2.split(img_hsv)\n",
        "\n",
        "# LAB (L*a*b*)\n",
        "img_lab = cv2.cvtColor(img_color, cv2.COLOR_BGR2LAB)\n",
        "l, a, b = cv2.split(img_lab)\n",
        "\n",
        "# YUV / YCbCr\n",
        "img_yuv = cv2.cvtColor(img_color, cv2.COLOR_BGR2YUV)\n",
        "y, u, v_comp = cv2.split(img_yuv)\n",
        "\n",
        "# XYZ\n",
        "img_xyz = cv2.cvtColor(img_color, cv2.COLOR_BGR2XYZ)\n",
        "x, y_comp, z = cv2.split(img_xyz)\n",
        "\n",
        "# Visualize different color spaces\n",
        "fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
        "\n",
        "# RGB\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title('RGB')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(r, cmap='Reds')\n",
        "axes[0,1].set_title('RGB - Red')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(g, cmap='Greens')\n",
        "axes[0,2].set_title('RGB - Green')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "# HSV\n",
        "axes[1,0].imshow(cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB))\n",
        "axes[1,0].set_title('HSV (converted to RGB for display)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(h, cmap='hsv')\n",
        "axes[1,1].set_title('HSV - Hue')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(s, cmap='gray')\n",
        "axes[1,2].set_title('HSV - Saturation')\n",
        "axes[1,2].axis('off')\n",
        "\n",
        "# LAB\n",
        "axes[2,0].imshow(cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB))\n",
        "axes[2,0].set_title('LAB (converted to RGB for display)')\n",
        "axes[2,0].axis('off')\n",
        "\n",
        "axes[2,1].imshow(l, cmap='gray')\n",
        "axes[2,1].set_title('LAB - L* (Lightness)')\n",
        "axes[2,1].axis('off')\n",
        "\n",
        "axes[2,2].imshow(a, cmap='RdYlGn')\n",
        "axes[2,2].set_title('LAB - a* (Green-Red)')\n",
        "axes[2,2].axis('off')\n",
        "\n",
        "# YUV\n",
        "axes[3,0].imshow(cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB))\n",
        "axes[3,0].set_title('YUV (converted to RGB for display)')\n",
        "axes[3,0].axis('off')\n",
        "\n",
        "axes[3,1].imshow(y, cmap='gray')\n",
        "axes[3,1].set_title('YUV - Y (Luminance)')\n",
        "axes[3,1].axis('off')\n",
        "\n",
        "axes[3,2].imshow(u, cmap='gray')\n",
        "axes[3,2].set_title('YUV - U (Chrominance)')\n",
        "axes[3,2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Color space comparison for specific tasks\n",
        "# Example: Skin detection in HSV\n",
        "lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
        "upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
        "skin_mask = cv2.inRange(img_hsv, lower_skin, upper_skin)\n",
        "skin_detected = cv2.bitwise_and(img_rgb, img_rgb, mask=skin_mask)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title('Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(skin_mask, cmap='gray')\n",
        "axes[1].set_title('Skin Detection Mask (HSV)')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(skin_detected)\n",
        "axes[2].set_title('Detected Skin')\n",
        "axes[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14. Berbagai Metode Segmentasi pada Citra\n",
        "\n",
        "Segmentasi adalah proses membagi citra menjadi region-region yang bermakna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Segmentation Methods\n",
        "# 1. Threshold-based Segmentation\n",
        "_, thresh_seg = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "# 2. Region Growing (using watershed as approximation)\n",
        "# Create markers\n",
        "_, markers = cv2.connectedComponents(thresh_seg)\n",
        "markers = markers + 1\n",
        "markers[thresh_seg == 0] = 0\n",
        "\n",
        "# Apply watershed\n",
        "img_for_watershed = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
        "cv2.watershed(img_for_watershed, markers)\n",
        "watershed_result = markers.astype(np.uint8)\n",
        "\n",
        "# 3. K-means Clustering Segmentation\n",
        "data = img_rgb.reshape((-1, 3))\n",
        "data = np.float32(data)\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n",
        "k = 4\n",
        "_, labels, centers = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "centers = np.uint8(centers)\n",
        "segmented_kmeans = centers[labels.flatten()]\n",
        "segmented_kmeans = segmented_kmeans.reshape(img_rgb.shape)\n",
        "\n",
        "# 4. Mean Shift Segmentation\n",
        "try:\n",
        "    from sklearn.cluster import MeanShift\n",
        "    data_reshaped = img_rgb.reshape((-1, 3))\n",
        "    ms = MeanShift(bandwidth=20, bin_seeding=True)\n",
        "    ms.fit(data_reshaped[:10000])  # Sample for speed\n",
        "    labels_ms = ms.predict(data_reshaped)\n",
        "    segmented_meanshift = ms.cluster_centers_[labels_ms].astype(np.uint8)\n",
        "    segmented_meanshift = segmented_meanshift.reshape(img_rgb.shape)\n",
        "except ImportError:\n",
        "    segmented_meanshift = img_rgb.copy()\n",
        "    print(\"sklearn required for Mean Shift\")\n",
        "\n",
        "# 5. GrabCut Segmentation\n",
        "mask = np.zeros(img_gray.shape[:2], np.uint8)\n",
        "bgdModel = np.zeros((1, 65), np.float64)\n",
        "fgdModel = np.zeros((1, 65), np.float64)\n",
        "rect = (50, 50, img_gray.shape[1]-100, img_gray.shape[0]-100)\n",
        "cv2.grabCut(img_rgb, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
        "mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
        "grabcut_result = img_rgb * mask2[:, :, np.newaxis]\n",
        "\n",
        "# 6. Contour-based Segmentation\n",
        "contours, _ = cv2.findContours(thresh_seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "img_contours = img_rgb.copy()\n",
        "cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 20))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(thresh_seg, cmap='gray')\n",
        "axes[0,1].set_title('Threshold Segmentation')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(segmented_kmeans)\n",
        "axes[1,0].set_title('K-means Clustering (k=4)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(segmented_meanshift)\n",
        "axes[1,1].set_title('Mean Shift Segmentation')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[2,0].imshow(grabcut_result)\n",
        "axes[2,0].set_title('GrabCut Segmentation')\n",
        "axes[2,0].axis('off')\n",
        "\n",
        "axes[2,1].imshow(img_contours)\n",
        "axes[2,1].set_title('Contour-based Segmentation')\n",
        "axes[2,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Advanced: SLIC Superpixels\n",
        "try:\n",
        "    from skimage.segmentation import slic, mark_boundaries\n",
        "    segments_slic = slic(img_rgb, n_segments=100, compactness=10, sigma=1)\n",
        "    img_slic = mark_boundaries(img_rgb, segments_slic)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
        "    axes[0].imshow(img_rgb)\n",
        "    axes[0].set_title('Original')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(img_slic)\n",
        "    axes[1].set_title('SLIC Superpixels (100 segments)')\n",
        "    axes[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except ImportError:\n",
        "    print(\"scikit-image required for SLIC superpixels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Compression Concepts\n",
        "import os\n",
        "\n",
        "# Original image size\n",
        "original_size = os.path.getsize(\"images/mandrill.jpg\") if os.path.exists(\"images/mandrill.jpg\") else 0\n",
        "print(f\"Original JPEG size: {original_size / 1024:.2f} KB\")\n",
        "\n",
        "# Save as different formats to compare\n",
        "cv2.imwrite(\"temp_original.png\", img_rgb)\n",
        "png_size = os.path.getsize(\"temp_original.png\") if os.path.exists(\"temp_original.png\") else 0\n",
        "print(f\"PNG (lossless) size: {png_size / 1024:.2f} KB\")\n",
        "\n",
        "# JPEG with different quality (lossy)\n",
        "cv2.imwrite(\"temp_jpeg_high.jpg\", img_rgb, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "cv2.imwrite(\"temp_jpeg_medium.jpg\", img_rgb, [cv2.IMWRITE_JPEG_QUALITY, 50])\n",
        "cv2.imwrite(\"temp_jpeg_low.jpg\", img_rgb, [cv2.IMWRITE_JPEG_QUALITY, 10])\n",
        "\n",
        "jpeg_high = os.path.getsize(\"temp_jpeg_high.jpg\") if os.path.exists(\"temp_jpeg_high.jpg\") else 0\n",
        "jpeg_medium = os.path.getsize(\"temp_jpeg_medium.jpg\") if os.path.exists(\"temp_jpeg_medium.jpg\") else 0\n",
        "jpeg_low = os.path.getsize(\"temp_jpeg_low.jpg\") if os.path.exists(\"temp_jpeg_low.jpg\") else 0\n",
        "\n",
        "print(f\"JPEG Quality 95: {jpeg_high / 1024:.2f} KB\")\n",
        "print(f\"JPEG Quality 50: {jpeg_medium / 1024:.2f} KB\")\n",
        "print(f\"JPEG Quality 10: {jpeg_low / 1024:.2f} KB\")\n",
        "\n",
        "# Load and compare\n",
        "img_jpeg_high = cv2.imread(\"temp_jpeg_high.jpg\")\n",
        "img_jpeg_high = cv2.cvtColor(img_jpeg_high, cv2.COLOR_BGR2RGB)\n",
        "img_jpeg_medium = cv2.imread(\"temp_jpeg_medium.jpg\")\n",
        "img_jpeg_medium = cv2.cvtColor(img_jpeg_medium, cv2.COLOR_BGR2RGB)\n",
        "img_jpeg_low = cv2.imread(\"temp_jpeg_low.jpg\")\n",
        "img_jpeg_low = cv2.cvtColor(img_jpeg_low, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes[0,0].imshow(img_rgb)\n",
        "axes[0,0].set_title(f'Original PNG\\n({png_size/1024:.1f} KB)')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(img_jpeg_high)\n",
        "axes[0,1].set_title(f'JPEG Quality 95\\n({jpeg_high/1024:.1f} KB)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(img_jpeg_medium)\n",
        "axes[1,0].set_title(f'JPEG Quality 50\\n({jpeg_medium/1024:.1f} KB)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(img_jpeg_low)\n",
        "axes[1,1].set_title(f'JPEG Quality 10\\n({jpeg_low/1024:.1f} KB)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate PSNR (Peak Signal-to-Noise Ratio)\n",
        "def calculate_psnr(img1, img2):\n",
        "    mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * np.log10(255.0 / np.sqrt(mse))\n",
        "\n",
        "psnr_high = calculate_psnr(img_rgb, img_jpeg_high)\n",
        "psnr_medium = calculate_psnr(img_rgb, img_jpeg_medium)\n",
        "psnr_low = calculate_psnr(img_rgb, img_jpeg_low)\n",
        "\n",
        "print(f\"\\nPSNR (Quality 95): {psnr_high:.2f} dB\")\n",
        "print(f\"PSNR (Quality 50): {psnr_medium:.2f} dB\")\n",
        "print(f\"PSNR (Quality 10): {psnr_low:.2f} dB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Lossless Compression: Huffman Coding, RLE, Arithmetic Coding\n",
        "\n",
        "Lossless compression mempertahankan semua informasi citra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lossless Compression Methods\n",
        "# Run-Length Encoding (RLE)\n",
        "def rle_encode(image):\n",
        "    \"\"\"Simple RLE encoding for demonstration\"\"\"\n",
        "    flat = image.flatten()\n",
        "    encoded = []\n",
        "    count = 1\n",
        "    for i in range(1, len(flat)):\n",
        "        if flat[i] == flat[i-1]:\n",
        "            count += 1\n",
        "        else:\n",
        "            encoded.append((flat[i-1], count))\n",
        "            count = 1\n",
        "    encoded.append((flat[-1], count))\n",
        "    return encoded\n",
        "\n",
        "def rle_decode(encoded, shape):\n",
        "    \"\"\"RLE decoding\"\"\"\n",
        "    decoded = []\n",
        "    for value, count in encoded:\n",
        "        decoded.extend([value] * count)\n",
        "    return np.array(decoded).reshape(shape)\n",
        "\n",
        "# Apply RLE to binary image\n",
        "binary_for_rle = (img_gray > 127).astype(np.uint8) * 255\n",
        "rle_encoded = rle_encode(binary_for_rle)\n",
        "rle_decoded = rle_decode(rle_encoded, binary_for_rle.shape)\n",
        "\n",
        "original_size_bits = binary_for_rle.size * 8\n",
        "rle_size_bits = len(rle_encoded) * (8 + 16)  # Approximate: value (8 bits) + count (16 bits)\n",
        "compression_ratio_rle = original_size_bits / rle_size_bits if rle_size_bits > 0 else 1\n",
        "\n",
        "print(f\"Original size: {original_size_bits} bits\")\n",
        "print(f\"RLE encoded size: {rle_size_bits} bits\")\n",
        "print(f\"Compression ratio: {compression_ratio_rle:.2f}:1\")\n",
        "\n",
        "# Verify lossless\n",
        "assert np.array_equal(binary_for_rle, rle_decoded), \"RLE should be lossless!\"\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(binary_for_rle, cmap='gray')\n",
        "axes[0].set_title('Original Binary Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(rle_decoded, cmap='gray')\n",
        "axes[1].set_title('RLE Decoded (Lossless)')\n",
        "axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Huffman Coding (simplified demonstration)\n",
        "from collections import Counter\n",
        "\n",
        "def simple_huffman_demo(image):\n",
        "    \"\"\"Demonstrate Huffman coding concept\"\"\"\n",
        "    # Count frequency of each pixel value\n",
        "    pixel_counts = Counter(image.flatten())\n",
        "    total_pixels = image.size\n",
        "    \n",
        "    # Calculate entropy (theoretical minimum bits per pixel)\n",
        "    entropy = -sum((count/total_pixels) * np.log2(count/total_pixels) \n",
        "                   for count in pixel_counts.values() if count > 0)\n",
        "    \n",
        "    return entropy, pixel_counts\n",
        "\n",
        "entropy, pixel_counts = simple_huffman_demo(img_gray)\n",
        "print(f\"\\nImage Entropy: {entropy:.2f} bits/pixel\")\n",
        "print(f\"Original: 8 bits/pixel\")\n",
        "print(f\"Theoretical compression: {8/entropy:.2f}:1 (if entropy < 8)\")\n",
        "\n",
        "# Note: Full Huffman implementation requires tree building and encoding\n",
        "# This is a simplified demonstration of the concept\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Lossy Compression: DFT, WHT, DCT, KLT\n",
        "\n",
        "Lossy compression menggunakan transformasi untuk mengurangi redundansi dengan mengorbankan beberapa informasi.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lossy Compression: Transform-based Methods\n",
        "# 1. DCT (Discrete Cosine Transform) - used in JPEG\n",
        "from scipy.fftpack import dct, idct\n",
        "\n",
        "def dct_compress(image, block_size=8, keep_ratio=0.1):\n",
        "    \"\"\"DCT-based compression\"\"\"\n",
        "    h, w = image.shape\n",
        "    compressed = np.zeros_like(image, dtype=float)\n",
        "    \n",
        "    for i in range(0, h, block_size):\n",
        "        for j in range(0, w, block_size):\n",
        "            block = image[i:i+block_size, j:j+block_size].astype(float) - 128\n",
        "            dct_block = dct(dct(block, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
        "            \n",
        "            # Keep only top coefficients\n",
        "            threshold = np.sort(np.abs(dct_block.flatten()))[-int(block_size*block_size*keep_ratio)]\n",
        "            dct_block[np.abs(dct_block) < threshold] = 0\n",
        "            \n",
        "            # Inverse DCT\n",
        "            idct_block = idct(idct(dct_block, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
        "            compressed[i:i+block_size, j:j+block_size] = idct_block + 128\n",
        "    \n",
        "    return np.clip(compressed, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Apply DCT compression with different ratios\n",
        "img_dct_10 = dct_compress(img_gray, keep_ratio=0.1)\n",
        "img_dct_5 = dct_compress(img_gray, keep_ratio=0.05)\n",
        "img_dct_1 = dct_compress(img_gray, keep_ratio=0.01)\n",
        "\n",
        "# 2. DFT Compression (already demonstrated, but for compression)\n",
        "f_transform = fft2(img_gray)\n",
        "f_shift = fftshift(f_transform)\n",
        "magnitude = np.abs(f_shift)\n",
        "\n",
        "# Keep only top frequencies\n",
        "keep_ratio_dft = 0.1\n",
        "threshold_dft = np.sort(magnitude.flatten())[-int(magnitude.size * keep_ratio_dft)]\n",
        "mask_dft = magnitude >= threshold_dft\n",
        "f_compressed = f_shift * mask_dft\n",
        "img_dft_compressed = np.abs(ifft2(ifftshift(f_compressed))).astype(np.uint8)\n",
        "\n",
        "# 3. Walsh-Hadamard Transform (WHT) - simplified\n",
        "def hadamard_matrix(n):\n",
        "    \"\"\"Generate Hadamard matrix\"\"\"\n",
        "    if n == 1:\n",
        "        return np.array([[1]])\n",
        "    h = hadamard_matrix(n // 2)\n",
        "    return np.block([[h, h], [h, -h]])\n",
        "\n",
        "# Note: Full WHT implementation is complex, showing concept\n",
        "try:\n",
        "    # Use scipy's hadamard if available\n",
        "    from scipy.linalg import hadamard\n",
        "    n = 8\n",
        "    H = hadamard(n)\n",
        "    # Apply to 8x8 blocks (simplified)\n",
        "    print(\"WHT: Using Hadamard transform for compression concept\")\n",
        "except:\n",
        "    print(\"WHT: Concept demonstrated (full implementation requires larger matrices)\")\n",
        "\n",
        "# Visualize compression results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0,0].imshow(img_gray, cmap='gray')\n",
        "axes[0,0].set_title('Original')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(img_dct_10, cmap='gray')\n",
        "axes[0,1].set_title('DCT (10% coefficients)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(img_dct_5, cmap='gray')\n",
        "axes[0,2].set_title('DCT (5% coefficients)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "axes[1,0].imshow(img_dct_1, cmap='gray')\n",
        "axes[1,0].set_title('DCT (1% coefficients)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(img_dft_compressed, cmap='gray')\n",
        "axes[1,1].set_title('DFT (10% frequencies)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "# Calculate compression metrics\n",
        "psnr_dct_10 = calculate_psnr(img_gray, img_dct_10)\n",
        "psnr_dct_5 = calculate_psnr(img_gray, img_dct_5)\n",
        "psnr_dct_1 = calculate_psnr(img_gray, img_dct_1)\n",
        "psnr_dft = calculate_psnr(img_gray, img_dft_compressed)\n",
        "\n",
        "axes[1,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nCompression Quality Metrics:\")\n",
        "print(f\"DCT (10%): PSNR = {psnr_dct_10:.2f} dB\")\n",
        "print(f\"DCT (5%): PSNR = {psnr_dct_5:.2f} dB\")\n",
        "print(f\"DCT (1%): PSNR = {psnr_dct_1:.2f} dB\")\n",
        "print(f\"DFT (10%): PSNR = {psnr_dft:.2f} dB\")\n",
        "\n",
        "# KLT (Karhunen-Loeve Transform / PCA) - Principal Component Analysis\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reshape image for PCA\n",
        "h, w = img_gray.shape\n",
        "img_flat = img_gray.reshape(-1, 1)\n",
        "pca = PCA(n_components=1)\n",
        "pca.fit(img_flat)\n",
        "img_pca = pca.inverse_transform(pca.transform(img_flat))\n",
        "img_pca = img_pca.reshape(h, w).astype(np.uint8)\n",
        "\n",
        "# For color image PCA\n",
        "img_rgb_flat = img_rgb.reshape(-1, 3)\n",
        "pca_rgb = PCA(n_components=50)  # Keep 50 principal components\n",
        "img_rgb_pca = pca_rgb.inverse_transform(pca_rgb.transform(img_rgb_flat))\n",
        "img_rgb_pca = np.clip(img_rgb_pca, 0, 255).astype(np.uint8)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(img_rgb, cmap='gray' if len(img_rgb.shape) == 2 else None)\n",
        "axes[0].set_title('Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_rgb_pca, cmap='gray' if len(img_rgb_pca.shape) == 2 else None)\n",
        "axes[1].set_title(f'PCA Compression (50 components, {pca_rgb.explained_variance_ratio_.sum()*100:.1f}% variance)')\n",
        "axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Applications of Digital Image Processing\n",
        "\n",
        "# 1. Medical Imaging Applications\n",
        "print(\"=== MEDICAL IMAGING APPLICATIONS ===\\n\")\n",
        "\n",
        "print(\"1. X-Ray Image Enhancement:\")\n",
        "print(\"   - Contrast enhancement untuk meningkatkan visibility\")\n",
        "print(\"   - Noise reduction untuk clarity\")\n",
        "print(\"   - Edge detection untuk identifikasi fractures\")\n",
        "\n",
        "print(\"\\n2. CT Scan Analysis:\")\n",
        "print(\"   - 3D reconstruction dari 2D slices\")\n",
        "print(\"   - Tumor detection dan segmentation\")\n",
        "print(\"   - Volume measurement\")\n",
        "\n",
        "print(\"\\n3. MRI Processing:\")\n",
        "print(\"   - Image registration untuk alignment\")\n",
        "print(\"   - Brain segmentation\")\n",
        "print(\"   - Functional MRI analysis\")\n",
        "\n",
        "print(\"\\n4. Ultrasound Imaging:\")\n",
        "print(\"   - Speckle noise reduction\")\n",
        "print(\"   - Fetal development monitoring\")\n",
        "print(\"   - Organ boundary detection\")\n",
        "\n",
        "# Simulate medical image processing\n",
        "# Create a synthetic medical-like image\n",
        "medical_synthetic = np.random.normal(128, 30, img_gray.shape).astype(np.uint8)\n",
        "medical_synthetic = cv2.GaussianBlur(medical_synthetic, (5, 5), 2)\n",
        "\n",
        "# Apply medical imaging techniques\n",
        "# Contrast enhancement\n",
        "medical_enhanced = cv2.equalizeHist(medical_synthetic)\n",
        "\n",
        "# Edge detection for structure identification\n",
        "medical_edges = cv2.Canny(medical_synthetic, 50, 150)\n",
        "\n",
        "# Segmentation\n",
        "_, medical_thresh = cv2.threshold(medical_synthetic, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes[0,0].imshow(medical_synthetic, cmap='gray')\n",
        "axes[0,0].set_title('Synthetic Medical Image')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(medical_enhanced, cmap='gray')\n",
        "axes[0,1].set_title('Enhanced (Histogram Equalization)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[1,0].imshow(medical_edges, cmap='gray')\n",
        "axes[1,0].set_title('Edge Detection (Structure Identification)')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(medical_thresh, cmap='gray')\n",
        "axes[1,1].set_title('Segmentation (Threshold)')\n",
        "axes[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. Scientific Applications\n",
        "print(\"\\n=== SCIENTIFIC APPLICATIONS ===\\n\")\n",
        "\n",
        "print(\"1. Astronomy:\")\n",
        "print(\"   - Star detection dan classification\")\n",
        "print(\"   - Galaxy morphology analysis\")\n",
        "print(\"   - Image stacking untuk noise reduction\")\n",
        "\n",
        "print(\"\\n2. Remote Sensing:\")\n",
        "print(\"   - Land use classification\")\n",
        "print(\"   - Vegetation index calculation\")\n",
        "print(\"   - Change detection\")\n",
        "\n",
        "print(\"\\n3. Microscopy:\")\n",
        "print(\"   - Cell counting dan analysis\")\n",
        "print(\"   - Particle size measurement\")\n",
        "print(\"   - Fluorescence imaging\")\n",
        "\n",
        "print(\"\\n4. Material Science:\")\n",
        "print(\"   - Grain size analysis\")\n",
        "print(\"   - Defect detection\")\n",
        "print(\"   - Surface texture analysis\")\n",
        "\n",
        "# Demonstrate remote sensing concept\n",
        "# Simulate multi-spectral image\n",
        "bands = []\n",
        "for i in range(3):\n",
        "    band = np.random.normal(100 + i*30, 20, img_gray.shape).astype(np.uint8)\n",
        "    bands.append(band)\n",
        "\n",
        "multispectral = np.stack(bands, axis=2)\n",
        "ndvi_like = ((bands[2].astype(float) - bands[0].astype(float)) / \n",
        "             (bands[2].astype(float) + bands[0].astype(float) + 1))\n",
        "ndvi_like = ((ndvi_like + 1) * 127.5).astype(np.uint8)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(multispectral)\n",
        "axes[0].set_title('Multi-spectral Image (Simulated)')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(ndvi_like, cmap='RdYlGn')\n",
        "axes[1].set_title('Vegetation Index (NDVI-like)')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(cv2.cvtColor(multispectral, cv2.COLOR_BGR2RGB))\n",
        "axes[2].set_title('Color Composite')\n",
        "axes[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Industrial Applications\n",
        "print(\"\\n=== INDUSTRIAL APPLICATIONS ===\\n\")\n",
        "\n",
        "print(\"1. Quality Control:\")\n",
        "print(\"   - Defect detection\")\n",
        "print(\"   - Dimensional measurement\")\n",
        "print(\"   - Surface inspection\")\n",
        "\n",
        "print(\"\\n2. Robotics:\")\n",
        "print(\"   - Object recognition\")\n",
        "print(\"   - Path planning\")\n",
        "print(\"   - Visual servoing\")\n",
        "\n",
        "print(\"\\n3. Security:\")\n",
        "print(\"   - Face recognition\")\n",
        "print(\"   - Motion detection\")\n",
        "print(\"   - License plate recognition\")\n",
        "\n",
        "# Demonstrate quality control concept\n",
        "# Create synthetic product image with defect\n",
        "product = np.ones((200, 200), dtype=np.uint8) * 200\n",
        "product[50:150, 50:150] = 180  # Main object\n",
        "product[90:110, 90:110] = 50   # Defect (darker region)\n",
        "\n",
        "# Detect defect\n",
        "_, product_binary = cv2.threshold(product, 150, 255, cv2.THRESH_BINARY)\n",
        "contours, _ = cv2.findContours(product_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "product_marked = cv2.cvtColor(product, cv2.COLOR_GRAY2RGB)\n",
        "cv2.drawContours(product_marked, contours, -1, (255, 0, 0), 2)\n",
        "\n",
        "# Mark defect\n",
        "defect_mask = product < 100\n",
        "product_marked[defect_mask] = [255, 0, 0]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(product, cmap='gray')\n",
        "axes[0].set_title('Product Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(product_binary, cmap='gray')\n",
        "axes[1].set_title('Segmentation')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(product_marked)\n",
        "axes[2].set_title('Defect Detection')\n",
        "axes[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# State of the Art in Digital Image Processing\n",
        "\n",
        "print(\"=== STATE OF THE ART TECHNIQUES ===\\n\")\n",
        "\n",
        "print(\"1. DEEP LEARNING FOR IMAGE PROCESSING:\")\n",
        "print(\"   - Convolutional Neural Networks (CNN) untuk classification\")\n",
        "print(\"   - U-Net untuk image segmentation\")\n",
        "print(\"   - GANs (Generative Adversarial Networks) untuk image generation\")\n",
        "print(\"   - Autoencoders untuk denoising dan compression\")\n",
        "print(\"   - Transfer learning untuk domain adaptation\")\n",
        "\n",
        "print(\"\\n2. COMPUTER VISION ADVANCES:\")\n",
        "print(\"   - Object detection: YOLO, R-CNN, SSD\")\n",
        "print(\"   - Semantic segmentation: DeepLab, FCN\")\n",
        "print(\"   - Instance segmentation: Mask R-CNN\")\n",
        "print(\"   - Pose estimation: OpenPose, MediaPipe\")\n",
        "\n",
        "print(\"\\n3. IMAGE ENHANCEMENT:\")\n",
        "print(\"   - Super-resolution: SRCNN, ESRGAN\")\n",
        "print(\"   - Denoising: DnCNN, Noise2Noise\")\n",
        "print(\"   - Style transfer: Neural Style Transfer\")\n",
        "print(\"   - Colorization: Deep colorization networks\")\n",
        "\n",
        "print(\"\\n4. MEDICAL IMAGING AI:\")\n",
        "print(\"   - Automated diagnosis: CNN untuk pathology detection\")\n",
        "print(\"   - Image registration: Deep learning-based registration\")\n",
        "print(\"   - 3D reconstruction: Deep learning dari 2D slices\")\n",
        "print(\"   - Anomaly detection: Autoencoders untuk anomaly detection\")\n",
        "\n",
        "# Demonstrate concept of modern techniques\n",
        "# 1. Super-resolution concept (using interpolation as approximation)\n",
        "img_small = cv2.resize(img_gray, (img_gray.shape[1]//4, img_gray.shape[0]//4))\n",
        "img_sr_bicubic = cv2.resize(img_small, (img_gray.shape[1], img_gray.shape[0]), \n",
        "                            interpolation=cv2.INTER_CUBIC)\n",
        "img_sr_lanczos = cv2.resize(img_small, (img_gray.shape[1], img_gray.shape[0]), \n",
        "                            interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "# 2. Denoising concept (using advanced filters)\n",
        "img_noisy_art = img_gray.copy()\n",
        "noise_art = np.random.normal(0, 30, img_gray.shape).astype(np.int16)\n",
        "img_noisy_art = np.clip(img_gray.astype(np.int16) + noise_art, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Advanced denoising\n",
        "img_denoised_nlm = cv2.fastNlMeansDenoising(img_noisy_art, None, 10, 7, 21)\n",
        "img_denoised_bilateral = cv2.bilateralFilter(img_noisy_art, 9, 75, 75)\n",
        "\n",
        "# 3. Style transfer concept (simplified - using color mapping)\n",
        "img_style = cv2.imread(\"images/mandrill.jpg\", cv2.IMREAD_COLOR)\n",
        "if img_style is not None:\n",
        "    img_style = cv2.cvtColor(img_style, cv2.COLOR_BGR2RGB)\n",
        "    # Apply color transfer (simplified style transfer)\n",
        "    img_style_gray = cv2.cvtColor(img_style, cv2.COLOR_RGB2GRAY)\n",
        "    img_style_transfer = exposure.match_histograms(img_rgb, img_style, channel_axis=2)\n",
        "else:\n",
        "    img_style_transfer = img_rgb.copy()\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "\n",
        "# Super-resolution\n",
        "axes[0,0].imshow(img_small, cmap='gray')\n",
        "axes[0,0].set_title('Low Resolution (1/4 size)')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "axes[0,1].imshow(img_sr_bicubic, cmap='gray')\n",
        "axes[0,1].set_title('Super-Resolution (Bicubic)')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "axes[0,2].imshow(img_gray, cmap='gray')\n",
        "axes[0,2].set_title('Original (Reference)')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "# Denoising\n",
        "axes[1,0].imshow(img_noisy_art, cmap='gray')\n",
        "axes[1,0].set_title('Noisy Image')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "axes[1,1].imshow(img_denoised_nlm, cmap='gray')\n",
        "axes[1,1].set_title('Denoised (Non-local Means)')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "axes[1,2].imshow(img_denoised_bilateral, cmap='gray')\n",
        "axes[1,2].set_title('Denoised (Bilateral)')\n",
        "axes[1,2].axis('off')\n",
        "\n",
        "# Style transfer\n",
        "axes[2,0].imshow(img_rgb)\n",
        "axes[2,0].set_title('Original')\n",
        "axes[2,0].axis('off')\n",
        "\n",
        "axes[2,1].imshow(img_style_transfer)\n",
        "axes[2,1].set_title('Style Transfer (Color)')\n",
        "axes[2,1].axis('off')\n",
        "\n",
        "axes[2,2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Modern feature detection (already shown SIFT, ORB)\n",
        "# Show modern alternatives\n",
        "print(\"\\n=== MODERN FEATURE DETECTION ===\")\n",
        "print(\"Traditional: SIFT, SURF, ORB\")\n",
        "print(\"Modern: Learned features dari deep networks\")\n",
        "print(\"   - SuperPoint: Learned feature detector\")\n",
        "print(\"   - D2-Net: Dense feature detection\")\n",
        "print(\"   - R2D2: Repeatable and Reliable Detector\")\n",
        "\n",
        "# 5. Segmentation advances\n",
        "print(\"\\n=== MODERN SEGMENTATION ===\")\n",
        "print(\"Traditional: Threshold, Region growing, Watershed\")\n",
        "print(\"Modern Deep Learning:\")\n",
        "print(\"   - U-Net: Medical image segmentation\")\n",
        "print(\"   - DeepLab: Semantic segmentation\")\n",
        "print(\"   - Mask R-CNN: Instance segmentation\")\n",
        "print(\"   - Segment Anything Model (SAM): Foundation model\")\n",
        "\n",
        "# Summary visualization\n",
        "techniques_summary = {\n",
        "    'Traditional': ['Thresholding', 'Edge Detection', 'Morphology', 'Filtering'],\n",
        "    'Classical ML': ['K-means', 'Mean Shift', 'SVM', 'Random Forest'],\n",
        "    'Deep Learning': ['CNN', 'U-Net', 'GANs', 'Transformers']\n",
        "}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "y_pos = np.arange(len(techniques_summary))\n",
        "categories = list(techniques_summary.keys())\n",
        "counts = [len(techniques_summary[k]) for k in categories]\n",
        "\n",
        "bars = ax.barh(categories, counts, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
        "ax.set_xlabel('Number of Techniques')\n",
        "ax.set_title('Evolution of Image Processing Techniques')\n",
        "ax.set_xlim(0, max(counts) + 1)\n",
        "\n",
        "for i, (category, count) in enumerate(zip(categories, counts)):\n",
        "    ax.text(count + 0.1, i, str(count), va='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== FUTURE DIRECTIONS ===\")\n",
        "print(\"1. Foundation Models: Large pre-trained models (e.g., SAM, CLIP)\")\n",
        "print(\"2. Few-shot Learning: Learning from limited data\")\n",
        "print(\"3. Explainable AI: Understanding model decisions\")\n",
        "print(\"4. Edge AI: Processing on mobile/embedded devices\")\n",
        "print(\"5. Multimodal Learning: Combining vision with other modalities\")\n",
        "print(\"6. Real-time Processing: Optimized algorithms for speed\")\n",
        "print(\"7. Privacy-preserving: Federated learning, differential privacy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kesimpulan\n",
        "\n",
        "Notebook ini telah mencakup materi lengkap Pengolahan Citra Digital (PCD) mulai dari konsep dasar hingga aplikasi modern. Topik yang dibahas meliputi:\n",
        "\n",
        "1. **Fundamental Concepts**: Definisi, level-level operasi, persepsi visual\n",
        "2. **Basic Operations**: Operasi geometrik, transformasi intensitas, histogram\n",
        "3. **Advanced Processing**: Morfologi, filtering, transformasi domain frekuensi\n",
        "4. **Feature Analysis**: Edge detection, feature detection dan description\n",
        "5. **Color Processing**: Trichromacy, transformasi warna, color spaces\n",
        "6. **Segmentation**: Berbagai metode segmentasi citra\n",
        "7. **Compression**: Lossless dan lossy compression techniques\n",
        "8. **Applications**: Aplikasi di berbagai bidang sains dan medical imaging\n",
        "9. **State of the Art**: Teknologi terdepan menggunakan deep learning\n",
        "\n",
        "Semua konsep dilengkapi dengan implementasi praktis menggunakan OpenCV, scikit-image, dan library Python lainnya.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup temporary files\n",
        "import os\n",
        "temp_files = [\"temp_original.png\", \"temp_jpeg_high.jpg\", \"temp_jpeg_medium.jpg\", \"temp_jpeg_low.jpg\"]\n",
        "for file in temp_files:\n",
        "    if os.path.exists(file):\n",
        "        try:\n",
        "            os.remove(file)\n",
        "            print(f\"Removed {file}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print(\"\\n=== NOTEBOOK SELESAI ===\")\n",
        "print(\"Semua materi PCD telah tercakup dalam notebook ini.\")\n",
        "print(\"Silakan jalankan setiap cell secara berurutan untuk melihat hasilnya.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pcd2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
